
# config file for running integration tests

trustedanalytics.atk {

  # we're using a different port so it won't interfere with a running local server
  api.port = 19099

  # use H2 for testing so that we'll have a fresh DB each time
  metastore.connection = ${trustedanalytics.atk.metastore.connection-h2}

  engine {

    local-libs = [ ]

    # TODO: Titan is not yet working
    # use Berkley for backing Titan, requires extra code in application to set storage.directory
    titan.load.storage.hostname = ""
    titan.load.storage.backend = "berkeleyje"
    titan.query.storage.hostname = ${trustedanalytics.atk.engine.titan.load.storage.hostname}
    titan.query.storage.backend = "berkeleyje"

    spark {
      # The URL for connecting to the Spark master server
      master = "local[8]"

      # true to re-use a SparkContext, this can be helpful for automated integration tests, not for customers.
      reuse-context = true
    }

// TODO: enable giraph in pseudo-distributed mode or some kind of local mode
//    hadoop {
//      mapred.job.tracker = "local"
//    }
//
//    giraph {
//      mapred.job.tracker = "localhost:19100"
//      giraph.SplitMasterWorker = false
//    }
  }
}