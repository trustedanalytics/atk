To compile the project and create the sample jars do
 mvn package
you should see a example-plugins.jar in the target directory.

The hello world plugin will add a method to the frame class that prints hello world.
The word-count plugin will add a method to the frame class that counts words in the frame.
The vertex-degree count plugin will add a method to the graph class that counts the vertex out-degree.


Installing plugins:

To add the plugins to your current installation of trusted analytics copy the example-plugins.jar to
/usr/lib/trustedanalytics/lib/

Update the ATK configuration file to load your plugin. Open /etc/trustedanalytics/rest-server/application.conf.
The top of the file should look similar to this:

# BEGIN REQUIRED SETTINGS

trustedanalytics.atk {
    #bind address - change to 0.0.0.0 to listen on all interfaces
    //api.host = "127.0.0.1"

    #bind port
    //api.port = 9099

    # The host name for the Postgresql database in which the metadata will be stored
    //metastore.connection-postgresql.host = "invalid-postgresql-host"
    //metastore.connection-postgresql.port = 5432
    //metastore.connection-postgresql.database = "atk_metastore"
    //metastore.connection-postgresql.username = "atkuser"
    //metastore.connection-postgresql.password = "myPassword"
    metastore.connection-postgresql.url = "jdbc:postgresql://"${trustedanalytics.atk.metastore.connection-postgresql.host}":"${trustedanalytics.atk.metastore.connection-postgresql.port}"/"${trustedanalytics.atk.metastore.connection-postgresql.database}

    # This allows for the use of postgres for a metastore. Service restarts will not affect the data stored in postgres
    metastore.connection = ${trustedanalytics.atk.metastore.connection-postgresql}

    # This allows the use of an in memory data store. Restarting the rest server will create a fresh database and any
    # data in the h2 DB will be lost
    //metastore.connection = ${trustedanalytics.atk.metastore.connection-h2}

    engine {

        # The hdfs URL where the trustedanalytics folder will be created
        # and which will be used as the starting point for any relative URLs
        fs.root = "hdfs://invalid-fsroot-host/user/atkuser"

        # The (comma separated, no spaces) Zookeeper hosts that
        # Comma separated list of host names with zookeeper role assigned
        titan.load.storage.hostname = "invalid-titan-host"
        # Zookeeper client port, defaults to 2181
        //titan.load.storage.port = "2181"

        # The URL for connecting to the Spark master server
        spark.master = "spark://invalid-spark-master:7077"

        spark.conf.properties {
            # Memory should be same or lower than what is listed as available in Cloudera Manager.
            # Values should generally be in gigabytes, e.g. "8g"
            spark.executor.memory = "invalid executor memory"
        }
    }

}

Inside the "engine {" tag add the following text.

"
trustedanalytics.atk.engine.plugin.command.archives += "example-plugins"
"

Now restart the trusted analytics service and try the code example below.

sudo service trustedanalytics restart


Sample code:

from trustedanalytics import *

#the default home directory is  hdfs://user/atkuser all the sample data sets are saved to hdfs://user/atkuser/datasets
dataset = r"datasets/movie_data_random.csv"

#csv schema definition
schema = [("user_id", int32),
          ("movie_id", int32),
          ("rating", int32),
          ("splits", str)]

csv_file = CsvFile(dataset, schema, skip_header_lines=1)

print "Building data frame"

frame = Frame(csv_file)

print "View auto-generated Python documentation for plugin"
help(frame.helloworld)

print "Run hello-world plugin"
frame.helloworld()
>>u'Frame says Hello World'

frame.helloworld("test")
>> u'Frame says test'

More examples are available in the python-examples folder.
